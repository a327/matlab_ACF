---------------------------------------------------------------------------
Training stage 0
Sampled 79464 windows from 6334 images.
Done sampling windows (time=418s).
Computing lambdas... done (time=2350s).
Extracting features... done (time=4876s).
Sampled 15000 windows from 640 images.
Done sampling windows (time=61s).
Extracting features... done (time=52s).
Training AdaBoost: nWeak= 32 nFtrs=24900 pos=158928 neg=15000
 i=  16 alpha=1.000 err=0.264 loss=6.77e-02
 i=  32 alpha=1.000 err=0.284 loss=1.14e-02
Done training err=0.0011 fp=0.0001 fn=0.0021 (t=388.8s).
Done training stage 0 (time=16931s).
---------------------------------------------------------------------------
Training stage 1
Sampled 11976 windows from 1245 images.
Done sampling windows (time=96s).
Extracting features... done (time=39s).
Training AdaBoost: nWeak=128 nFtrs=24900 pos=158928 neg=25000
 i=  16 alpha=1.000 err=0.348 loss=1.99e-01
 i=  32 alpha=1.000 err=0.344 loss=7.34e-02
 i=  48 alpha=1.000 err=0.349 loss=2.92e-02
 i=  64 alpha=1.000 err=0.348 loss=1.17e-02
 i=  80 alpha=1.000 err=0.343 loss=4.58e-03
 i=  96 alpha=1.000 err=0.344 loss=1.80e-03
 i= 112 alpha=1.000 err=0.347 loss=6.99e-04
 i= 128 alpha=1.000 err=0.337 loss=2.79e-04
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=1093.7s).
Done training stage 1 (time=1235s).
---------------------------------------------------------------------------
Training stage 2
Sampled 4504 windows from 1245 images.
Done sampling windows (time=92s).
Extracting features... done (time=12s).
Training AdaBoost: nWeak=512 nFtrs=24900 pos=158928 neg=25000
 i=  16 alpha=1.000 err=0.337 loss=2.32e-01
 i=  32 alpha=1.000 err=0.341 loss=1.01e-01
 i=  48 alpha=1.000 err=0.364 loss=4.65e-02
 i=  64 alpha=1.000 err=0.367 loss=2.14e-02
 i=  80 alpha=1.000 err=0.343 loss=1.00e-02
 i=  96 alpha=1.000 err=0.378 loss=4.55e-03
 i= 112 alpha=1.000 err=0.366 loss=2.07e-03
 i= 128 alpha=1.000 err=0.363 loss=9.67e-04
 i= 144 alpha=1.000 err=0.347 loss=4.36e-04
 i= 160 alpha=1.000 err=0.351 loss=1.95e-04
 i= 176 alpha=1.000 err=0.374 loss=9.20e-05
 i= 192 alpha=1.000 err=0.351 loss=4.30e-05
 i= 208 alpha=1.000 err=0.341 loss=1.99e-05
 i= 224 alpha=1.000 err=0.368 loss=8.90e-06
 i= 240 alpha=1.000 err=0.354 loss=4.16e-06
 i= 256 alpha=1.000 err=0.366 loss=1.94e-06
 i= 272 alpha=1.000 err=0.368 loss=8.97e-07
 i= 288 alpha=1.000 err=0.350 loss=4.13e-07
 i= 304 alpha=1.000 err=0.359 loss=1.82e-07
 i= 320 alpha=1.000 err=0.355 loss=8.29e-08
 i= 336 alpha=1.000 err=0.371 loss=3.77e-08
 i= 352 alpha=1.000 err=0.351 loss=1.71e-08
 i= 368 alpha=1.000 err=0.372 loss=7.97e-09
 i= 384 alpha=1.000 err=0.367 loss=3.66e-09
 i= 400 alpha=1.000 err=0.360 loss=1.74e-09
 i= 416 alpha=1.000 err=0.359 loss=7.83e-10
 i= 432 alpha=1.000 err=0.370 loss=3.55e-10
 i= 448 alpha=1.000 err=0.353 loss=1.60e-10
 i= 464 alpha=1.000 err=0.348 loss=7.28e-11
 i= 480 alpha=1.000 err=0.367 loss=3.29e-11
 i= 496 alpha=1.000 err=0.345 loss=1.46e-11
 i= 512 alpha=1.000 err=0.349 loss=6.45e-12
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=1461.3s).
Done training stage 2 (time=1603s).
---------------------------------------------------------------------------
Training stage 3
Sampled 1400 windows from 1245 images.
Done sampling windows (time=67s).
Extracting features... done (time=3s).
Training AdaBoost: nWeak=2048 nFtrs=24900 pos=158928 neg=25000
 i=  16 alpha=1.000 err=0.336 loss=2.54e-01
 i=  32 alpha=1.000 err=0.364 loss=1.16e-01
 i=  48 alpha=1.000 err=0.367 loss=5.73e-02
 i=  64 alpha=1.000 err=0.376 loss=2.81e-02
 i=  80 alpha=1.000 err=0.368 loss=1.38e-02
 i=  96 alpha=1.000 err=0.354 loss=6.75e-03
 i= 112 alpha=1.000 err=0.358 loss=3.31e-03
 i= 128 alpha=1.000 err=0.357 loss=1.56e-03
 i= 144 alpha=1.000 err=0.371 loss=7.49e-04
 i= 160 alpha=1.000 err=0.364 loss=3.60e-04
 i= 176 alpha=1.000 err=0.373 loss=1.81e-04
 i= 192 alpha=1.000 err=0.355 loss=9.07e-05
 i= 208 alpha=1.000 err=0.357 loss=4.48e-05
 i= 224 alpha=1.000 err=0.350 loss=2.13e-05
 i= 240 alpha=1.000 err=0.358 loss=1.03e-05
 i= 256 alpha=1.000 err=0.367 loss=5.13e-06
 i= 272 alpha=1.000 err=0.352 loss=2.53e-06
 i= 288 alpha=1.000 err=0.364 loss=1.20e-06
 i= 304 alpha=1.000 err=0.366 loss=5.88e-07
 i= 320 alpha=1.000 err=0.375 loss=2.85e-07
 i= 336 alpha=1.000 err=0.363 loss=1.40e-07
 i= 352 alpha=1.000 err=0.359 loss=6.67e-08
 i= 368 alpha=1.000 err=0.369 loss=3.36e-08
 i= 384 alpha=1.000 err=0.373 loss=1.63e-08
 i= 400 alpha=1.000 err=0.366 loss=7.69e-09
 i= 416 alpha=1.000 err=0.365 loss=3.70e-09
 i= 432 alpha=1.000 err=0.372 loss=1.82e-09
 i= 448 alpha=1.000 err=0.353 loss=8.80e-10
 i= 464 alpha=1.000 err=0.361 loss=4.27e-10
 i= 480 alpha=1.000 err=0.365 loss=2.01e-10
 i= 496 alpha=1.000 err=0.372 loss=9.90e-11
 i= 512 alpha=1.000 err=0.360 loss=4.97e-11
 i= 528 alpha=1.000 err=0.367 loss=2.43e-11
 i= 544 alpha=1.000 err=0.360 loss=1.17e-11
 i= 560 alpha=1.000 err=0.360 loss=5.70e-12
 i= 576 alpha=1.000 err=0.351 loss=2.65e-12
 i= 592 alpha=1.000 err=0.367 loss=1.30e-12
 i= 608 alpha=1.000 err=0.362 loss=6.12e-13
 i= 624 alpha=1.000 err=0.361 loss=2.89e-13
 i= 640 alpha=1.000 err=0.359 loss=1.40e-13
 i= 656 alpha=1.000 err=0.366 loss=6.79e-14
 i= 672 alpha=1.000 err=0.368 loss=3.29e-14
 i= 688 alpha=1.000 err=0.377 loss=1.55e-14
 i= 704 alpha=1.000 err=0.366 loss=7.61e-15
 i= 720 alpha=1.000 err=0.367 loss=3.58e-15
 i= 736 alpha=1.000 err=0.376 loss=1.76e-15
 i= 752 alpha=1.000 err=0.360 loss=8.32e-16
 i= 768 alpha=1.000 err=0.364 loss=3.94e-16
 i= 784 alpha=1.000 err=0.354 loss=1.85e-16
 i= 800 alpha=1.000 err=0.373 loss=8.94e-17
 i= 816 alpha=1.000 err=0.365 loss=4.47e-17
 i= 832 alpha=1.000 err=0.330 loss=2.13e-17
 i= 848 alpha=1.000 err=0.367 loss=9.92e-18
 i= 864 alpha=1.000 err=0.367 loss=4.77e-18
 i= 880 alpha=1.000 err=0.346 loss=2.30e-18
 i= 896 alpha=1.000 err=0.367 loss=1.09e-18
 i= 912 alpha=1.000 err=0.343 loss=5.23e-19
 i= 928 alpha=1.000 err=0.371 loss=2.43e-19
 i= 944 alpha=1.000 err=0.367 loss=1.17e-19
 i= 960 alpha=1.000 err=0.358 loss=5.63e-20
 i= 976 alpha=1.000 err=0.359 loss=2.73e-20
 i= 992 alpha=1.000 err=0.366 loss=1.33e-20
 i=1008 alpha=1.000 err=0.366 loss=6.42e-21
 i=1024 alpha=1.000 err=0.384 loss=3.10e-21
 i=1040 alpha=1.000 err=0.366 loss=1.51e-21
 i=1056 alpha=1.000 err=0.367 loss=7.25e-22
 i=1072 alpha=1.000 err=0.367 loss=3.52e-22
 i=1088 alpha=1.000 err=0.366 loss=1.67e-22
 i=1104 alpha=1.000 err=0.366 loss=8.21e-23
 i=1120 alpha=1.000 err=0.377 loss=4.00e-23
 i=1136 alpha=1.000 err=0.366 loss=1.88e-23
 i=1152 alpha=1.000 err=0.377 loss=8.97e-24
 i=1168 alpha=1.000 err=0.367 loss=4.21e-24
 i=1184 alpha=1.000 err=0.368 loss=2.08e-24
 i=1200 alpha=1.000 err=0.358 loss=9.82e-25
 i=1216 alpha=1.000 err=0.359 loss=4.65e-25
 i=1232 alpha=1.000 err=0.362 loss=2.16e-25
 i=1248 alpha=1.000 err=0.363 loss=1.01e-25
 i=1264 alpha=1.000 err=0.370 loss=4.81e-26
 i=1280 alpha=1.000 err=0.367 loss=2.30e-26
 i=1296 alpha=1.000 err=0.376 loss=1.09e-26
 i=1312 alpha=1.000 err=0.362 loss=5.21e-27
 i=1328 alpha=1.000 err=0.354 loss=2.47e-27
 i=1344 alpha=1.000 err=0.372 loss=1.20e-27
 i=1360 alpha=1.000 err=0.344 loss=5.63e-28
 i=1376 alpha=1.000 err=0.377 loss=2.69e-28
 i=1392 alpha=1.000 err=0.379 loss=1.29e-28
 i=1408 alpha=1.000 err=0.362 loss=6.20e-29
 i=1424 alpha=1.000 err=0.359 loss=2.97e-29
 i=1440 alpha=1.000 err=0.371 loss=1.40e-29
 i=1456 alpha=1.000 err=0.372 loss=6.71e-30
 i=1472 alpha=1.000 err=0.372 loss=3.24e-30
 i=1488 alpha=1.000 err=0.365 loss=1.63e-30
 i=1504 alpha=1.000 err=0.373 loss=7.83e-31
 i=1520 alpha=1.000 err=0.356 loss=3.69e-31
 i=1536 alpha=1.000 err=0.373 loss=1.73e-31
 i=1552 alpha=1.000 err=0.364 loss=8.26e-32
 i=1568 alpha=1.000 err=0.376 loss=3.98e-32
 i=1584 alpha=1.000 err=0.372 loss=1.96e-32
 i=1600 alpha=1.000 err=0.352 loss=9.40e-33
 i=1616 alpha=1.000 err=0.355 loss=4.46e-33
 i=1632 alpha=1.000 err=0.347 loss=2.10e-33
 i=1648 alpha=1.000 err=0.366 loss=9.96e-34
 i=1664 alpha=1.000 err=0.358 loss=4.67e-34
 i=1680 alpha=1.000 err=0.373 loss=2.23e-34
 i=1696 alpha=1.000 err=0.368 loss=1.06e-34
 i=1712 alpha=1.000 err=0.365 loss=5.05e-35
 i=1728 alpha=1.000 err=0.369 loss=2.45e-35
 i=1744 alpha=1.000 err=0.377 loss=1.20e-35
 i=1760 alpha=1.000 err=0.355 loss=5.55e-36
 i=1776 alpha=1.000 err=0.373 loss=2.67e-36
 i=1792 alpha=1.000 err=0.358 loss=1.30e-36
 i=1808 alpha=1.000 err=0.379 loss=6.15e-37
 i=1824 alpha=1.000 err=0.358 loss=2.95e-37
 i=1840 alpha=1.000 err=0.366 loss=1.42e-37
 i=1856 alpha=1.000 err=0.369 loss=6.95e-38
 i=1872 alpha=1.000 err=0.369 loss=3.35e-38
 i=1888 alpha=1.000 err=0.375 loss=1.63e-38
 i=1904 alpha=1.000 err=0.372 loss=7.97e-39
 i=1920 alpha=1.000 err=0.367 loss=3.71e-39
 i=1936 alpha=1.000 err=0.367 loss=1.75e-39
 i=1952 alpha=1.000 err=0.363 loss=8.51e-40
 i=1968 alpha=1.000 err=0.355 loss=3.91e-40
 i=1984 alpha=1.000 err=0.375 loss=1.90e-40
 stopping early
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=3318.5s).
Done training stage 3 (time=3426s).
---------------------------------------------------------------------------
Done training (time=23196s).
